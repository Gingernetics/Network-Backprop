You have to run it for many thousands of generations in order to get anything decent. Based on some projects I've seen, they only start to get good at around 1500-2000 generations, after 5000 or 10000 they are really good, even with standard triple layered perceptron (input, hidden, output). Some of the more advanced ones use multiple hidden layers, and after 5000 or 10000 generations are easily much better than even the top 5% of human players. Better yet was this one project I saw a couple months back where he did a base multi layer neural network with a triple layered dopaminergic simulation combined with a working and long term memory simulation, with a simple thalamus to control the activation of long term memory and activate the associated reward pathways. There were 3 levels of these to allow for higher order long term memory representations, and associated higher order rewards. After 6500 generations it could out perform any human player with ease. The score was the fitness function and the increase in score relative to it's last game determine the magnitude of the reward input. The initial generations had this base neural network structure, with random weights. Each network would play 200 rounds of 2048, with the end performance determining their fitness. The fittest 25% would "mate", with a predetermined code determining how their characteristics mixed. During each mating session there was a predetermined probability of  a mutation happening, which would alter the number of neurons, or rarely create a new layer all together, or alter the connections. The final generation of neural networks had a modified long term memory system, with a double layered thalamus, a quadraple layered hidden layer group, and a weird gating system that would modulate the reward system and the thalamus, downregulating it's activity for some reason.ï»¿
